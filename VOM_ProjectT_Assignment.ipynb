{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VOM_ProjectT_Assignment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ABvXDy1ER4f"
      },
      "source": [
        "# **Best Practices for Writing/Documenting code**\n",
        "## **Introduction**\n",
        "This coding assignment will get you used to writing code efficiently as well as documenting your code through various exercises such as efficient data cleaning and Pandas code, as well as designing reusable data workflows. Remember to document all code you write in this assignment, as that will be part of your grade as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezK6KYrkFYJ_"
      },
      "source": [
        "## **Setup**\n",
        "The following code will import libraries that will be useful for this assignment.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfmIzgmNFpdS",
        "outputId": "f1a5005c-0afb-472f-c606-d368ce72729a"
      },
      "source": [
        "!pip install pdpipe\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import timeit\n",
        "import pdpipe\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdpipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/d1/494d8d173d5c20ef745ea81c20a1edbb194c632866a996f13b946ce44146/pdpipe-0.0.53-py3-none-any.whl (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hCollecting strct\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/24/62efe536ba1bedb8591fb83ef4d5bcdaca4147a7bfefff3e77aba1061d79/strct-0.0.32-py2.py3-none-any.whl\n",
            "Collecting skutil>=0.0.15\n",
            "  Downloading https://files.pythonhosted.org/packages/34/2b/1b5c9e7be3c24e1bd5ce35c2d27a5780989c3d90fcee10f3fee3074dda7f/skutil-0.0.16-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from pdpipe) (2.3.0)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pdpipe) (1.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pdpipe) (4.41.1)\n",
            "Collecting decore\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/69/9e3da3a87058d43e5b9f0f668f69da591b8b0c2763b3afbfea084582ea57/decore-0.0.1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from skutil>=0.0.15->pdpipe) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pdpipe) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pdpipe) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.0->pdpipe) (1.15.0)\n",
            "Building wheels for collected packages: decore\n",
            "  Building wheel for decore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for decore: filename=decore-0.0.1-py2.py3-none-any.whl size=4190 sha256=200e0aec08eb84dae34bb10ea6436d5c777c03b8a0e4ef5b9ae74570e0288240\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/1b/9c/71fa8b5df01cc605c4b5cadcd81df76d520149ca5c02b4013b\n",
            "Successfully built decore\n",
            "Installing collected packages: strct, decore, skutil, pdpipe\n",
            "Successfully installed decore-0.0.1 pdpipe-0.0.53 skutil-0.0.16 strct-0.0.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT5io0EKnK5K"
      },
      "source": [
        "## **Shortcuts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8rBUo3VmTel"
      },
      "source": [
        "\n",
        "Even if you are familiar with Jupyter, you are strongly encouraged to become proficient with keyboard shortcuts (this will save you time in the future). To learn about keyboard shortcuts, go to **Help --> Keyboard Shortcuts** in the menu above. \n",
        "\n",
        "Here are a few that we like:\n",
        "1. `Ctrl` + `Return` : *Evaluate the current cell*\n",
        "1. `Shift` + `Return`: *Evaluate the current cell and move to the next*\n",
        "1. `ESC` : *command mode* (may need to press before using any of the commands below)\n",
        "1. `a` : *create a cell above*\n",
        "1. `b` : *create a cell below*\n",
        "1. `dd` : *delete a cell*\n",
        "1. `z` : *undo the last cell operation*\n",
        "1. `m` : *convert a cell to markdown*\n",
        "1. `y` : *convert a cell to code*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Vr3Dp_IEef"
      },
      "source": [
        "# **Importing Datasets**\n",
        "The following code will import datasets used in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "3qmENXOoIXcq",
        "outputId": "27e3806a-019e-490e-e397-dc53d9c79d2c"
      },
      "source": [
        "#next 2 lines temperary\n",
        "url = 'https://raw.githubusercontent.com/vikashraja24/cs189projectTfinal/main/biostats.csv'\n",
        "biostats = pd.read_csv(url)\n",
        "#biostats = pd.read_csv('biostats.csv')\n",
        "\n",
        "#next 2 lines temperary\n",
        "url = 'https://raw.githubusercontent.com/vikashraja24/cs189projectTfinal/main/BL-Flickr-Images-Book.csv'\n",
        "books = pd.read_csv(url)\n",
        "#books = pd.read_csv('BL-Flickr-Images-Book.csv')\n",
        "\n",
        "#next 2 lines temperary\n",
        "url = 'https://raw.githubusercontent.com/vikashraja24/cs189projectTfinal/main/USA_Housing.csv'\n",
        "housing = pd.read_csv(url)\n",
        "#housing = pd.read_csv('USA_Housing.csv')\n",
        "housing"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "      <th>Address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79545.458574</td>\n",
              "      <td>5.682861</td>\n",
              "      <td>7.009188</td>\n",
              "      <td>4.09</td>\n",
              "      <td>23086.800503</td>\n",
              "      <td>1.059034e+06</td>\n",
              "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79248.642455</td>\n",
              "      <td>6.002900</td>\n",
              "      <td>6.730821</td>\n",
              "      <td>3.09</td>\n",
              "      <td>40173.072174</td>\n",
              "      <td>1.505891e+06</td>\n",
              "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61287.067179</td>\n",
              "      <td>5.865890</td>\n",
              "      <td>8.512727</td>\n",
              "      <td>5.13</td>\n",
              "      <td>36882.159400</td>\n",
              "      <td>1.058988e+06</td>\n",
              "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63345.240046</td>\n",
              "      <td>7.188236</td>\n",
              "      <td>5.586729</td>\n",
              "      <td>3.26</td>\n",
              "      <td>34310.242831</td>\n",
              "      <td>1.260617e+06</td>\n",
              "      <td>USS Barnett\\nFPO AP 44820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59982.197226</td>\n",
              "      <td>5.040555</td>\n",
              "      <td>7.839388</td>\n",
              "      <td>4.23</td>\n",
              "      <td>26354.109472</td>\n",
              "      <td>6.309435e+05</td>\n",
              "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>60567.944140</td>\n",
              "      <td>7.830362</td>\n",
              "      <td>6.137356</td>\n",
              "      <td>3.46</td>\n",
              "      <td>22837.361035</td>\n",
              "      <td>1.060194e+06</td>\n",
              "      <td>USNS Williams\\nFPO AP 30153-7653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>78491.275435</td>\n",
              "      <td>6.999135</td>\n",
              "      <td>6.576763</td>\n",
              "      <td>4.02</td>\n",
              "      <td>25616.115489</td>\n",
              "      <td>1.482618e+06</td>\n",
              "      <td>PSC 9258, Box 8489\\nAPO AA 42991-3352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>63390.686886</td>\n",
              "      <td>7.250591</td>\n",
              "      <td>4.805081</td>\n",
              "      <td>2.13</td>\n",
              "      <td>33266.145490</td>\n",
              "      <td>1.030730e+06</td>\n",
              "      <td>4215 Tracy Garden Suite 076\\nJoshualand, VA 01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>68001.331235</td>\n",
              "      <td>5.534388</td>\n",
              "      <td>7.130144</td>\n",
              "      <td>5.44</td>\n",
              "      <td>42625.620156</td>\n",
              "      <td>1.198657e+06</td>\n",
              "      <td>USS Wallace\\nFPO AE 73316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>65510.581804</td>\n",
              "      <td>5.992305</td>\n",
              "      <td>6.792336</td>\n",
              "      <td>4.07</td>\n",
              "      <td>46501.283803</td>\n",
              "      <td>1.298950e+06</td>\n",
              "      <td>37778 George Ridges Apt. 509\\nEast Holly, NV 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Avg. Area Income  ...                                            Address\n",
              "0         79545.458574  ...  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...\n",
              "1         79248.642455  ...  188 Johnson Views Suite 079\\nLake Kathleen, CA...\n",
              "2         61287.067179  ...  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...\n",
              "3         63345.240046  ...                          USS Barnett\\nFPO AP 44820\n",
              "4         59982.197226  ...                         USNS Raymond\\nFPO AE 09386\n",
              "...                ...  ...                                                ...\n",
              "4995      60567.944140  ...                   USNS Williams\\nFPO AP 30153-7653\n",
              "4996      78491.275435  ...              PSC 9258, Box 8489\\nAPO AA 42991-3352\n",
              "4997      63390.686886  ...  4215 Tracy Garden Suite 076\\nJoshualand, VA 01...\n",
              "4998      68001.331235  ...                          USS Wallace\\nFPO AE 73316\n",
              "4999      65510.581804  ...  37778 George Ridges Apt. 509\\nEast Holly, NV 2...\n",
              "\n",
              "[5000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUJwcwjpOvrj"
      },
      "source": [
        "##  **1. Efficient Pandas**\n",
        "In this question, you will do some exercises in writing Pandas code efficiently, and you will to learn to speed up code when filtering and modifying data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6WSBIy8MGE4"
      },
      "source": [
        "First, load and examine the biostats dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ffFnYjCbMGNe",
        "outputId": "dc233a37-fc27-4702-91a7-44d8dcb74589"
      },
      "source": [
        "biostats"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>\"Sex\"</th>\n",
              "      <th>\"Age\"</th>\n",
              "      <th>\"Height (in)\"</th>\n",
              "      <th>\"Weight (lbs)\"</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alex</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>41</td>\n",
              "      <td>74</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bert</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>42</td>\n",
              "      <td>68</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carl</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>32</td>\n",
              "      <td>70</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dave</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>39</td>\n",
              "      <td>72</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Elly</td>\n",
              "      <td>\"F\"</td>\n",
              "      <td>30</td>\n",
              "      <td>66</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Fran</td>\n",
              "      <td>\"F\"</td>\n",
              "      <td>33</td>\n",
              "      <td>66</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gwen</td>\n",
              "      <td>\"F\"</td>\n",
              "      <td>26</td>\n",
              "      <td>64</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hank</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>30</td>\n",
              "      <td>71</td>\n",
              "      <td>158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ivan</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>53</td>\n",
              "      <td>72</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Jake</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>32</td>\n",
              "      <td>69</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Kate</td>\n",
              "      <td>\"F\"</td>\n",
              "      <td>47</td>\n",
              "      <td>69</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Luke</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>34</td>\n",
              "      <td>72</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Myra</td>\n",
              "      <td>\"F\"</td>\n",
              "      <td>23</td>\n",
              "      <td>62</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Neil</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>36</td>\n",
              "      <td>75</td>\n",
              "      <td>160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Omar</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>38</td>\n",
              "      <td>70</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Page</td>\n",
              "      <td>\"F\"</td>\n",
              "      <td>31</td>\n",
              "      <td>67</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Quin</td>\n",
              "      <td>\"M\"</td>\n",
              "      <td>29</td>\n",
              "      <td>71</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Ruth</td>\n",
              "      <td>\"F\"</td>\n",
              "      <td>28</td>\n",
              "      <td>65</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Name       \"Sex\"   \"Age\"   \"Height (in)\"   \"Weight (lbs)\"\n",
              "0   Alex         \"M\"      41              74              170\n",
              "1   Bert         \"M\"      42              68              166\n",
              "2   Carl         \"M\"      32              70              155\n",
              "3   Dave         \"M\"      39              72              167\n",
              "4   Elly         \"F\"      30              66              124\n",
              "5   Fran         \"F\"      33              66              115\n",
              "6   Gwen         \"F\"      26              64              121\n",
              "7   Hank         \"M\"      30              71              158\n",
              "8   Ivan         \"M\"      53              72              175\n",
              "9   Jake         \"M\"      32              69              143\n",
              "10  Kate         \"F\"      47              69              139\n",
              "11  Luke         \"M\"      34              72              163\n",
              "12  Myra         \"F\"      23              62               98\n",
              "13  Neil         \"M\"      36              75              160\n",
              "14  Omar         \"M\"      38              70              145\n",
              "15  Page         \"F\"      31              67              135\n",
              "16  Quin         \"M\"      29              71              176\n",
              "17  Ruth         \"F\"      28              65              131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVSGp1HLlRmJ"
      },
      "source": [
        "**a)** Part of writing good code means readablilty, and often times datasets have issues of bad column names. Please clean the biostats dataset to have column names [Name, Sex, Age, Height, Weight]. Be sure to document any helper functions or processes in your code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYOjVGSDPOZF"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "\n",
        "### end code ###\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6HSziey2VxD"
      },
      "source": [
        "**b)** In this part, you will write two ways of finding the average height of people 30 or older. In this first cell, do not use any Pandas filtering or aggregation methods, and in the second cell, use Pandas method to get the same answer in one line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYJ6CO7s2UDz"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvmvJMZzHp4z"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3fOOrYqMG0s"
      },
      "source": [
        "**c)** Now please time the execution of both methods above to verify the effeciency of the second block.\n",
        "\n",
        "Hint: check out the timeit library\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwBzNmNmQGeR"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DePvGhG9QHlD"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EltIbQqzRKM5"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "##  **2. Pipelines**\n",
        "In this question, you will do some exercises dealing with data pipelines with the housing data. When talking about the best practices of writing and documenting code in the machine learning context, efficient data pipelines allow for reusable data workflows. The true beauty in pipelines is that it automates repetitive tasks and speeds up the data cleaning. As a machine learning engineer, you may take be tasked to clean and filter multiple datasets. An efficient practice in this case is using pipelines. \n",
        "\n",
        "**Hint**: read notes about pdpipe library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obNtoPV-L_Tp"
      },
      "source": [
        "First, load and examine the housing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "3wceoHbDL_cV",
        "outputId": "025f95d8-3f1f-42f9-a667-9564c3298d91"
      },
      "source": [
        "housing"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "      <th>Address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79545.458574</td>\n",
              "      <td>5.682861</td>\n",
              "      <td>7.009188</td>\n",
              "      <td>4.09</td>\n",
              "      <td>23086.800503</td>\n",
              "      <td>1.059034e+06</td>\n",
              "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79248.642455</td>\n",
              "      <td>6.002900</td>\n",
              "      <td>6.730821</td>\n",
              "      <td>3.09</td>\n",
              "      <td>40173.072174</td>\n",
              "      <td>1.505891e+06</td>\n",
              "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61287.067179</td>\n",
              "      <td>5.865890</td>\n",
              "      <td>8.512727</td>\n",
              "      <td>5.13</td>\n",
              "      <td>36882.159400</td>\n",
              "      <td>1.058988e+06</td>\n",
              "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63345.240046</td>\n",
              "      <td>7.188236</td>\n",
              "      <td>5.586729</td>\n",
              "      <td>3.26</td>\n",
              "      <td>34310.242831</td>\n",
              "      <td>1.260617e+06</td>\n",
              "      <td>USS Barnett\\nFPO AP 44820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59982.197226</td>\n",
              "      <td>5.040555</td>\n",
              "      <td>7.839388</td>\n",
              "      <td>4.23</td>\n",
              "      <td>26354.109472</td>\n",
              "      <td>6.309435e+05</td>\n",
              "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>60567.944140</td>\n",
              "      <td>7.830362</td>\n",
              "      <td>6.137356</td>\n",
              "      <td>3.46</td>\n",
              "      <td>22837.361035</td>\n",
              "      <td>1.060194e+06</td>\n",
              "      <td>USNS Williams\\nFPO AP 30153-7653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>78491.275435</td>\n",
              "      <td>6.999135</td>\n",
              "      <td>6.576763</td>\n",
              "      <td>4.02</td>\n",
              "      <td>25616.115489</td>\n",
              "      <td>1.482618e+06</td>\n",
              "      <td>PSC 9258, Box 8489\\nAPO AA 42991-3352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>63390.686886</td>\n",
              "      <td>7.250591</td>\n",
              "      <td>4.805081</td>\n",
              "      <td>2.13</td>\n",
              "      <td>33266.145490</td>\n",
              "      <td>1.030730e+06</td>\n",
              "      <td>4215 Tracy Garden Suite 076\\nJoshualand, VA 01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>68001.331235</td>\n",
              "      <td>5.534388</td>\n",
              "      <td>7.130144</td>\n",
              "      <td>5.44</td>\n",
              "      <td>42625.620156</td>\n",
              "      <td>1.198657e+06</td>\n",
              "      <td>USS Wallace\\nFPO AE 73316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>65510.581804</td>\n",
              "      <td>5.992305</td>\n",
              "      <td>6.792336</td>\n",
              "      <td>4.07</td>\n",
              "      <td>46501.283803</td>\n",
              "      <td>1.298950e+06</td>\n",
              "      <td>37778 George Ridges Apt. 509\\nEast Holly, NV 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Avg. Area Income  ...                                            Address\n",
              "0         79545.458574  ...  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...\n",
              "1         79248.642455  ...  188 Johnson Views Suite 079\\nLake Kathleen, CA...\n",
              "2         61287.067179  ...  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...\n",
              "3         63345.240046  ...                          USS Barnett\\nFPO AP 44820\n",
              "4         59982.197226  ...                         USNS Raymond\\nFPO AE 09386\n",
              "...                ...  ...                                                ...\n",
              "4995      60567.944140  ...                   USNS Williams\\nFPO AP 30153-7653\n",
              "4996      78491.275435  ...              PSC 9258, Box 8489\\nAPO AA 42991-3352\n",
              "4997      63390.686886  ...  4215 Tracy Garden Suite 076\\nJoshualand, VA 01...\n",
              "4998      68001.331235  ...                          USS Wallace\\nFPO AE 73316\n",
              "4999      65510.581804  ...  37778 George Ridges Apt. 509\\nEast Holly, NV 2...\n",
              "\n",
              "[5000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eNWxgukSLR7"
      },
      "source": [
        "**a)** To start off, create a column called 'Price Range', which categorizes the prices in 3 ranges of low, medium, and high based on the intervals [0, 250000], [250000, 750000], [750000, inf]. Please use a helper function and follow proper style and naming conventions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvCKcz4ISKRM"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjDCxFneSmkS"
      },
      "source": [
        "**b)** Now, let's assume the Address is useless for the proposed machine learning model. Use a one stage pipeline to drop it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6cCCg3RSnJS"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMMBX9mjZYHL"
      },
      "source": [
        "**c)** Now, lets take advantage of the true power of pipelines. Let's say the requirement for data cleaning are to drop the number of bedrooms column, drop the area population column, and then use one-hot-encoding on the price range column. Use one pipeline to make these changes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vef_jfplZYVs"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjztvuPrgdqq"
      },
      "source": [
        "Now, you should be able to see how these small modules of pipelines can be similar across datasets for cleaning specifications and how this practice can be lead very efficient, readable, and reusable code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bh5jvjj3rN"
      },
      "source": [
        "##  **3. Efficient Practices to Visualize Code**\n",
        " Now you will take a look at efficient pracitces for graphing, inlcuding documenting, labeling, and scaling graphs based on the results needed.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBzNT6c4kA9a"
      },
      "source": [
        "**a)** Let's examine the relationship between the average income and the price of a house in the housing data. Use a scatter plot to plot price vs income for the first 100 entries in the data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6RepSpdj3_I"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI3Lp5NllfF-"
      },
      "source": [
        "**b)** Now, looking at the correlation, you may see that the scales make it hard to recognize the details of the correlation. Include an appropriate scaled axis to make the correlation more aligned to the unity line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa2Nrlvglfhy"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7O4ZKFumra8"
      },
      "source": [
        "**c)** Now, using appropiate practices of documentation and labeling, include labels for axes and title for the plot taking into account the scaling you did in part b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fujEfoehmrnq"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPeNzM5cE_ng"
      },
      "source": [
        "##  **4. Cleaning Data Efficiently with Documentation**\n",
        "In this problem, you will walk through cleaning a messy dataset, incorporating the efficient pracitices of writing and documenting code that you have learned so far. For documentation purposes, keep a dictionary of keys removed and modified that keeps tracks of all processes done on the dataset throughout the cleaning process. Use appropriate comments on all functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7kTtY0GLR6c"
      },
      "source": [
        "First, load and examine the books dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCg816wELZeK",
        "outputId": "c8696352-0f59-46ab-9b63-309d6f3c2525"
      },
      "source": [
        "cleaning_updates = {'remove': [], 'modify': []}\n",
        "books"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Identifier</th>\n",
              "      <th>Edition Statement</th>\n",
              "      <th>Place of Publication</th>\n",
              "      <th>Date of Publication</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Title</th>\n",
              "      <th>Author</th>\n",
              "      <th>Contributors</th>\n",
              "      <th>Corporate Author</th>\n",
              "      <th>Corporate Contributors</th>\n",
              "      <th>Former owner</th>\n",
              "      <th>Engraver</th>\n",
              "      <th>Issuance type</th>\n",
              "      <th>Flickr URL</th>\n",
              "      <th>Shelfmarks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>1879 [1878]</td>\n",
              "      <td>S. Tinsley &amp; Co.</td>\n",
              "      <td>Walter Forbes. [A novel.] By A. A</td>\n",
              "      <td>A. A.</td>\n",
              "      <td>FORBES, Walter.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS 12641.b.30.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>216</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London; Virtue &amp; Yorston</td>\n",
              "      <td>1868</td>\n",
              "      <td>Virtue &amp; Co.</td>\n",
              "      <td>All for Greed. [A novel. The dedication signed...</td>\n",
              "      <td>A., A. A.</td>\n",
              "      <td>BLAZE DE BURY, Marie Pauline Rose - Baroness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS 12626.cc.2.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>1869</td>\n",
              "      <td>Bradbury, Evans &amp; Co.</td>\n",
              "      <td>Love the Avenger. By the author of “All for Gr...</td>\n",
              "      <td>A., A. A.</td>\n",
              "      <td>BLAZE DE BURY, Marie Pauline Rose - Baroness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS 12625.dd.1.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>472</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>1851</td>\n",
              "      <td>James Darling</td>\n",
              "      <td>Welsh Sketches, chiefly ecclesiastical, to the...</td>\n",
              "      <td>A., E. S.</td>\n",
              "      <td>Appleyard, Ernest Silvanus.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS 10369.bbb.15.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>480</td>\n",
              "      <td>A new edition, revised, etc.</td>\n",
              "      <td>London</td>\n",
              "      <td>1857</td>\n",
              "      <td>Wertheim &amp; Macintosh</td>\n",
              "      <td>[The World in which I live, and my place in it...</td>\n",
              "      <td>A., E. S.</td>\n",
              "      <td>BROOME, John Henry.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS 9007.d.28.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8282</th>\n",
              "      <td>4158088</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>1838</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Parochial History of Cornwall, founded on,...</td>\n",
              "      <td>GIDDY, afterwards GILBERT, Davies.</td>\n",
              "      <td>BOASE, Henry Samuel.|HALS, William.|LYSONS, Da...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS|British Library HMNTS 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8283</th>\n",
              "      <td>4158128</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Derby</td>\n",
              "      <td>1831, 32</td>\n",
              "      <td>M. Mozley &amp; Son</td>\n",
              "      <td>The History and Gazetteer of the County of Der...</td>\n",
              "      <td>GLOVER, Stephen - of Derby</td>\n",
              "      <td>NOBLE, Thomas.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS|British Library HMNTS 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8284</th>\n",
              "      <td>4159563</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>[1806]-22</td>\n",
              "      <td>T. Cadell and W. Davies</td>\n",
              "      <td>Magna Britannia; being a concise topographical...</td>\n",
              "      <td>LYSONS, Daniel - M.A., F.R.S., and LYSONS (Sam...</td>\n",
              "      <td>GREGSON, Matthew.|LYSONS, Samuel - F.R.S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS|British Library HMNTS 19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8285</th>\n",
              "      <td>4159587</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Newcastle upon Tyne</td>\n",
              "      <td>1834</td>\n",
              "      <td>Mackenzie &amp; Dent</td>\n",
              "      <td>An historical, topographical and descriptive v...</td>\n",
              "      <td>Mackenzie, E. (Eneas)</td>\n",
              "      <td>ROSS, M. - of Durham</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>monographic</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS|British Library HMNTS 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8286</th>\n",
              "      <td>4160339</td>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>1834-43</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Collectanea Topographica et Genealogica. [Firs...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BANDINEL, Bulkeley.|Nichols, John Gough</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>continuing</td>\n",
              "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
              "      <td>British Library HMNTS|British Library HMNTS 79...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8287 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Identifier  ...                                         Shelfmarks\n",
              "0            206  ...                  British Library HMNTS 12641.b.30.\n",
              "1            216  ...                  British Library HMNTS 12626.cc.2.\n",
              "2            218  ...                  British Library HMNTS 12625.dd.1.\n",
              "3            472  ...                British Library HMNTS 10369.bbb.15.\n",
              "4            480  ...                   British Library HMNTS 9007.d.28.\n",
              "...          ...  ...                                                ...\n",
              "8282     4158088  ...  British Library HMNTS|British Library HMNTS 10...\n",
              "8283     4158128  ...  British Library HMNTS|British Library HMNTS 10...\n",
              "8284     4159563  ...  British Library HMNTS|British Library HMNTS 19...\n",
              "8285     4159587  ...  British Library HMNTS|British Library HMNTS 10...\n",
              "8286     4160339  ...  British Library HMNTS|British Library HMNTS 79...\n",
              "\n",
              "[8287 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iil7t61h85bk"
      },
      "source": [
        "**a)** First find and print all columns that contain any sort of empty values. However, if Author has empty values, replace those with the empty string. Update the cleaning_updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpTJbJDu85mJ"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4CvV5hqFMp6"
      },
      "source": [
        "**b)** Now, drop all the columns that need to be removed, due to not having complete data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl2E34BbFMw9"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_tzFHoG4rq"
      },
      "source": [
        "**c)** Remove the unnecessary brackets in the title names efficiently. Remember to practice good documentation and use of helper methods for readable and reproducible code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc3egogRG4zA"
      },
      "source": [
        "### start code ###\n",
        "\n",
        "### end code ###"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IPMb0LCSbR3",
        "outputId": "dcaa4b07-8d89-4f6a-d2bc-2c9fbe5814e4"
      },
      "source": [
        "cleaning_updates"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'modify': [], 'remove': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMyjPRiuSSB0"
      },
      "source": [
        "Going through the cleaning process with reusable blocks of code as well as documenting any changes to the intial data set is a good practice of documentation in the data cleaning context."
      ]
    }
  ]
}